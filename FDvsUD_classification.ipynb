{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDvsUD_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPfixNP+lW4TcSeKY5j60VP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eborsi/BIOL468/blob/master/FDvsUD_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTgQykf9pCiF",
        "colab_type": "text"
      },
      "source": [
        "#**Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCuLsyeBfogB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import dirname, join \n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "#import tools for data visualization\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "#import classifiers and tools from sci-kit learn library\n",
        "from sklearn import datasets, svm, preprocessing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_curve, recall_score, precision_score, make_scorer, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "\n",
        "#import libraries for CNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjYFOtV23BKW",
        "colab_type": "code",
        "outputId": "694001e1-18fb-49d6-921f-ff8352d419f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#import and mount google drive (where .mat files are located)\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmjoOFZUpOYY",
        "colab_type": "text"
      },
      "source": [
        "#**Loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCfT_NcuEzSK",
        "colab_type": "code",
        "outputId": "ced310a8-11df-407c-81e9-f410a2e749d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# loading .mat files for all birds & motifs\n",
        "data_dir = '/content/drive/My Drive/BIOL 468/HCTSA mat files' #change to directory where mat files are stored\n",
        "#python dictionary representing the dataset, formatted as such : {'bird1_ID':['motif1',...,['motifn'], 'bird2_ID':['motif1',...,['motifn']}\n",
        "motifs_dict = {'bk109-re22or7': ['abcd','ef'],\n",
        "               'bk110-re30or6': ['ef'], \n",
        "               'bk142-re4pu': ['abc','dfbe'],\n",
        "               'bl62gr62': ['abc','qed'],\n",
        "               'p38y02': ['bacde','bqqaq','fgha'],\n",
        "               'p77y27': ['abcdef'],\n",
        "               're26or': ['abcd','be'],\n",
        "               'w34r14': ['abc','abe']\n",
        "              }\n",
        "#load_matfiles() takes a dictionary of motifs as argument \n",
        "#the data should be stored in this architecture: data_dir/bird_ID/motif/HCTSA_*.mat\n",
        "#load_matfiles() returns an array of tuples of the form (mat file, name of file)\n",
        "matFiles = load_matfiles(motifs_dict)\n",
        "#matToDataframe() loads the Time Series data from the HCTSA_*.mat files into Pandas dataframes\n",
        "#and attaches the encoded labels ('UD'->0 and 'FD'->1) and the dataset tag (birdID_motif)\n",
        "dataframes = [matToDataframe(matfile,filename) for (matfile,filename) in matFiles]\n",
        "#pd.concat() concatenates all the dataframes for individual motifs into a single large dataframe\n",
        "concat_df = pd.concat(dataframes, ignore_index=True, sort=False).dropna(axis=1)\n",
        "\n",
        "print(\"First 5 rows of the complete dataframe: \\n\", concat_df.head())\n",
        "\n",
        "make_PCA_plot(concat_df)  #generates a PCA plot with n=2 principal components from the concatenated dataframe to visualize the data\n",
        "make_tSNE_plot(concat_df)  #generates a plot of the data after a PCA (n=50) and a t-SNE (n=2 dimensions)\n",
        "\n",
        "X_train, y_train, X_test, y_test, IDs_train, IDs_test = split_TrainTest(concat_df, motifs_dict, 'p38y02', 'bacde')\n",
        "\n",
        "print(concat_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 rows of the complete dataframe: \n",
            "           1         2         4  ...      7873  y          bird_motif\n",
            "0  0.281693  0.430784  0.311264  ...  0.092443  1  bk109-re22or7_abcd\n",
            "1  0.141843  1.000000  0.820295  ...  0.900822  1  bk109-re22or7_abcd\n",
            "2  0.221615  0.287441  0.080510  ...  0.022543  1  bk109-re22or7_abcd\n",
            "3  0.341237  0.609037  0.185116  ...  0.712741  1  bk109-re22or7_abcd\n",
            "4  0.135395  0.690432  0.080510  ...  0.707577  1  bk109-re22or7_abcd\n",
            "\n",
            "[5 rows x 5954 columns]\n",
            "(615, 5952) (615,) (92, 5952) (92,) (615,) (92,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8m_Pm8cm4tL",
        "colab_type": "text"
      },
      "source": [
        "#**Helper functions**\n",
        "##For loading, pre-processing and visualizing data\n",
        "\n",
        "\n",
        "> Contains the functions:\n",
        "\n",
        "*   matToDataframe()\n",
        "*   dfToNumpy()\n",
        "*   load_matfiles()\n",
        "*   split_TrainTest()\n",
        "*   list_motifs_from_dict()\n",
        "*   make_PCA_plot()\n",
        "*   make_tSNE_plot()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2FRJ-ZEQm1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matToDataframe(matfile, filename):\n",
        "  DataMat = matfile['TS_DataMat']\n",
        "  CatMat = matfile['TimeSeries']['Group']\n",
        "  y_column = np.zeros(CatMat.shape[0]).astype(int)\n",
        "  for i in range(CatMat.shape[0]):\n",
        "    if int(CatMat[i][0][0][0])==2:\n",
        "      y_column[i] = 1\n",
        "    else:\n",
        "      y_column[i] = 0\n",
        "  #print(DataMat.shape, y_column.shape)\n",
        "  op_IDs_mat = matfile['Operations']['ID']\n",
        "  op_IDs = [str(op_IDs_mat[i][0][0][0]) for i in range(op_IDs_mat.shape[0])]\n",
        "  df = pd.DataFrame.from_dict(DataMat)\n",
        "  df.columns = op_IDs\n",
        "  df['y'] = y_column\n",
        "  df['bird_motif'] = filename\n",
        "  return df\n",
        "\n",
        "def dfToNumpy(df):\n",
        "  X = np.array(df.iloc[:,:-2])\n",
        "  Y = np.array(df['y'])\n",
        "  IDs = np.array(df['bird_motif'])\n",
        "  return X,Y,IDs\n",
        "\n",
        "def load_matfiles(motifs_dict):\n",
        "  matFiles = []\n",
        "  filenames = []\n",
        "  for bird in motifs_dict.keys():\n",
        "    for motif in motifs_dict[bird]:\n",
        "      mat_filename = 'HCTSA_' + bird + '_' + motif + '_N.mat'\n",
        "      mat_filepath = join(data_dir, bird, motif, mat_filename)\n",
        "      matFile = scipy.io.loadmat(mat_filepath)\n",
        "      matFiles.append(matFile)\n",
        "      filenames.append(''+ bird + '_' + motif)\n",
        "  return zip(matFiles, filenames)\n",
        "\n",
        "def split_TrainTest(df, motifs_dict, test_bird, test_motif):\n",
        "  test_bird_motif = ''+test_bird+'_'+test_motif\n",
        "  df_test = df.loc[df['bird_motif'] == test_bird_motif]\n",
        "  df_train = df.copy()\n",
        "  for motif in motifs_dict[test_bird]:\n",
        "    motif_ID = ''+test_bird+'_'+motif\n",
        "    df_train = df_train.drop(df_train[df_train['bird_motif']==motif_ID].index)\n",
        "  X_train, y_train, IDs_train = dfToNumpy(df_train)\n",
        "  X_test, y_test, IDs_test = dfToNumpy(df_test)\n",
        "  return X_train, y_train, X_test, y_test, IDs_train, IDs_test\n",
        "\n",
        "def split_TrainTest_indiv(df, motifs_dict, test_bird, test_motif):\n",
        "  bird_motifs = motifs_dict[test_bird]\n",
        "  df_train = pd.DataFrame()\n",
        "  for motif in bird_motifs:\n",
        "    bird_motif_tag = ''+test_bird+'_'+motif\n",
        "    df_motif = df.loc[df['bird_motif'] == bird_motif_tag]\n",
        "    if (motif==test_motif):\n",
        "      df_test = df_motif\n",
        "    else:\n",
        "      df_train = pd.concat([df_train,df_motif])\n",
        "  X_train, y_train, IDs_train = dfToNumpy(df_train)\n",
        "  X_test, y_test, IDs_test = dfToNumpy(df_test)\n",
        "  return X_train, y_train, X_test, y_test, IDs_train, IDs_test  \n",
        "\n",
        "def list_motifs_from_dict(motifs_dict):\n",
        "  list_motifs = []\n",
        "  for bird in motifs_dict:\n",
        "    for motif in motifs_dict[bird]:\n",
        "      bird_motif = ''+bird+'_'+motif\n",
        "      list_motifs.append(bird_motif)\n",
        "  return list_motifs\n",
        "\n",
        "def make_PCA_plot(df, color_per_motif = True):\n",
        "  X,y,IDs = dfToNumpy(df)\n",
        "  y_label = np.copy(y).astype(str)\n",
        "  y_label[y_label == '0'] = 'UD'\n",
        "  y_label[y_label == '1'] = 'FD'\n",
        "  nb_motifs = len(np.unique(IDs))\n",
        "  pca = PCA(n_components=2)\n",
        "  pca_result = pca.fit_transform(X)\n",
        "  #df['pca-one'] = pca_result[:,0]\n",
        "  #df['pca-two'] = pca_result[:,1] \n",
        "  print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "  plt.figure(figsize=(8,5))\n",
        "  ax = sns.scatterplot(\n",
        "    x=pca_result[:,0], y= pca_result[:,1],\n",
        "    style=y_label,\n",
        "    hue=IDs,\n",
        "    palette=sns.color_palette(\"Paired\",nb_motifs), \n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        "    #ax=ax\n",
        "  )\n",
        "  legend = plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), ncol=1)\n",
        "  ax.set(xlabel='Principal component 1', ylabel='Principal component 2')\n",
        "  plt.title('PCA on whole dataset (colour-coded by motif)')\n",
        "  plt.savefig('PCA_incomplete_colors.png', bbox_extra_artists=(legend,), bbox_inches='tight')\n",
        "  files.download('PCA_incomplete_colors.png')\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(8,5))\n",
        "  ax2 = sns.scatterplot(\n",
        "      x=pca_result[:,0], y=pca_result[:,1],\n",
        "      style=y_label,\n",
        "      hue=y_label,\n",
        "      #palette=sns.color_palette(\"hls\", 2),\n",
        "      legend=\"full\",\n",
        "      alpha=0.5,\n",
        "      \n",
        "  )\n",
        "  legend2 = plt.legend(loc='best', ncol=1)\n",
        "  ax2.set(xlabel='Principal component 1', ylabel='Principal component 2')\n",
        "  plt.title('PCA on whole dataset')\n",
        "  plt.savefig('PCA_plot.png',  bbox_inches='tight')\n",
        "  files.download('PCA_plot.png')\n",
        "\n",
        "def make_tSNE_plot(df):\n",
        "  X,y,IDs = dfToNumpy(df)\n",
        "  y_label = np.copy(y).astype(str)\n",
        "  y_label[y_label == '0'] = 'UD'\n",
        "  y_label[y_label == '1'] = 'FD'\n",
        "  nb_motifs = len(np.unique(IDs))\n",
        "  time_start = time.time()\n",
        "  pca_50 = PCA(n_components=50)\n",
        "  pca_result_50 = pca_50.fit_transform(X)\n",
        "  print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
        "  tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
        "  tsne_pca_results = tsne.fit_transform(pca_result_50)\n",
        "  print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n",
        "  plt.figure(figsize=(8,5))\n",
        "  ax = sns.scatterplot(\n",
        "    x=tsne_pca_results[:,0], y= tsne_pca_results[:,1],\n",
        "    style=y_label,\n",
        "    hue=IDs,\n",
        "    palette=sns.color_palette(\"Paired\",nb_motifs), \n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        "    #ax=ax\n",
        "  )\n",
        "  legend = plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), ncol=1)\n",
        "  ax.set(xlabel='Dimension 1', ylabel='Dimension 2')\n",
        "  plt.title('t-SNE on whole dataset (colour-coded by motif)')\n",
        "  plt.savefig('tSNE_plot_colors.png', bbox_extra_artists=(legend,), bbox_inches='tight')\n",
        "  files.download('tSNE_plot_colors.png')\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(8,5))\n",
        "  ax2 = sns.scatterplot(\n",
        "      x=tsne_pca_results[:,0], y= tsne_pca_results[:,1],\n",
        "      style=y_label,\n",
        "      hue=y_label,\n",
        "      #palette=sns.color_palette(\"hls\", 2),\n",
        "      legend=\"full\",\n",
        "      alpha=0.5,\n",
        "      \n",
        "  )\n",
        "  legend2 = plt.legend(loc='best', ncol=1)\n",
        "  ax2.set(xlabel='Dimension 1', ylabel='Dimension 2')\n",
        "  plt.title('t-SNE on whole dataset')\n",
        "  plt.savefig('tSNE_plot.png',  bbox_inches='tight')\n",
        "  files.download('tSNE_plot.png')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kLKIHaZRro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_TrainTest_indiv(df, motifs_dict, test_bird, test_motif):\n",
        "  #build train set:\n",
        "  bird_motifs = motifs_dict[test_bird]\n",
        "  df_train = pd.DataFrame()\n",
        "  for motif in bird_motifs:\n",
        "    print(motif)\n",
        "    bird_motif_tag = ''+test_bird+'_'+motif\n",
        "    df_motif = df.loc[df['bird_motif'] == bird_motif_tag]\n",
        "    #print(df_motif.head())\n",
        "    if (motif==test_motif):\n",
        "      df_test = df_motif\n",
        "    else:\n",
        "      df_train = pd.concat([df_train,df_motif])\n",
        "  X_train, y_train, IDs_train = dfToNumpy(df_train)\n",
        "  X_test, y_test, IDs_test = dfToNumpy(df_test)\n",
        "  return X_train, y_train, X_test, y_test, IDs_train, IDs_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwOvMWV-A3aV",
        "colab_type": "text"
      },
      "source": [
        "# **Hyperparameter optimization**\n",
        "\n",
        "##Optimization of hyperparameters using exhaustive search approach (or gridsearch) for different binary classifiers:\n",
        "*   LinearSVC\n",
        "*   SVC\n",
        "*   Logistic Regression \n",
        "*   Naive Bayes\n",
        "*   Decision Tree (no bagging)\n",
        "*   Decision Tree (with bagging)\n",
        "*   AdaBoost\n",
        "*   Random Forest\n",
        "*   Stochastic Gradient Descent (SGD) classifiers\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMKr5mp8nasA",
        "colab_type": "text"
      },
      "source": [
        "##Linear SVC "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYxp81a6fyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: Linear SVC #\n",
        "LinSVM_param_grid = [   {'C':[0.001, 0.01, 0.1, 1, 5, 10], 'max_iter': [100, 1000, 10000]}\n",
        "                    ]\n",
        "print(\"# LinearSVC: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(LinearSVC(), LinSVM_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QCZ8P-Jnevn",
        "colab_type": "text"
      },
      "source": [
        "##SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA6Cpqp-xh7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: SVC #\n",
        "SVC_clf = SVC()\n",
        "print(SVC_clf.get_params())\n",
        "SVC_param_grid = [{'kernel':['linear','rbf','sigmoid'], 'C':[0.001, 0.01, 0.1, 1, 5, 10]}]\n",
        "                          \n",
        "print(\"# SVC Classifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(SVC(), SVC_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRBYf7vOnhWh",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4cAfCTSPIgm",
        "colab_type": "code",
        "outputId": "3f3e5783-8e02-4b13-ec12-bcf5582c062f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# MODEL: Logistic Regression #\n",
        "LogReg_param_grid = [{'C':[0.0001,0.001, 0.01], 'max_iter': [100,100000], 'solver': ['lbfgs','saga','liblinear'],'multi_class':['ovr']},\n",
        "                     {'C':[0.001], 'max_iter': [1000], 'penalty': ['l1','l2'], 'solver': ['liblinear'],'multi_class':['ovr']},\n",
        "                     {'C':[0.001], 'max_iter': [1000], 'dual': [True], 'penalty': ['l2'], 'solver': ['liblinear'],'multi_class':['ovr']}\n",
        "                    ]\n",
        "print(\"# LogisticRegression: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "#scores = ['accuracy','precision', 'recall']\n",
        "scores = ['accuracy']\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(LogisticRegression(), LogReg_param_grid, cv=20, scoring='%s' % score, verbose = 10)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# LogisticRegression: Tuning hyper-parameters for accuracy\n",
            "\n",
            "# Tuning hyper-parameters for accuracy\n",
            "\n",
            "Fitting 20 folds for each of 21 candidates, totalling 420 fits\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.769, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.808, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.654, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.680, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.640, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs ...........\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.769, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.846, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.692, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.440, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.440, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.760, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.680, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.640, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   0.8s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=1.000, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   0.8s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   0.8s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=saga ............\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=saga, score=0.760, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.769, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.846, total=   0.3s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.692, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.440, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.440, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.760, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.640, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.640, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=1.000, total=   0.3s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear .......\n",
            "[CV]  C=0.0001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.769, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.808, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.654, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.680, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.640, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs ........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.1s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.769, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.846, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.692, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.480, total=   0.8s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.440, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.440, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.760, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.680, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.640, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=1.000, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   0.8s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=saga .........\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=saga, score=0.760, total=   0.7s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.769, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.846, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.692, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.440, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.440, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.760, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.640, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.640, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=1.000, total=   0.3s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear ....\n",
            "[CV]  C=0.0001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.923, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.846, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.731, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.560, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.640, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs ............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.720, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.923, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.846, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.731, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.560, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.520, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.440, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.760, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.640, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.480, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=1.000, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.840, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.920, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.920, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=saga .............\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=saga, score=0.720, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.923, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.846, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.731, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.560, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.520, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.440, total=   0.4s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.760, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.640, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=1.000, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.920, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.920, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100, multi_class=ovr, solver=liblinear ........\n",
            "[CV]  C=0.001, max_iter=100, multi_class=ovr, solver=liblinear, score=0.720, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.923, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.846, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.731, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.560, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.1s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.440, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.640, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs .........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.720, total=   0.2s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.923, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.846, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.731, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.560, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.520, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.440, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.760, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.640, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.480, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=1.000, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   0.6s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.840, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.920, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.920, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=saga ..........\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=saga, score=0.720, total=   0.7s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.923, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.846, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.731, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.560, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.520, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.440, total=   0.4s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.760, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.640, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=1.000, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.920, total=   0.4s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.920, total=   0.4s\n",
            "[CV] C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear .....\n",
            "[CV]  C=0.001, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.720, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.885, total=   0.3s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.654, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.731, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.560, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.600, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.3s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.600, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.3s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.3s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.960, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.885, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.654, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.731, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.560, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.520, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.600, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.760, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.600, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.520, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.800, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=1.000, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.840, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.920, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.880, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.960, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.920, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=saga ..............\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=saga, score=0.760, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.885, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.654, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.731, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.560, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.520, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.600, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.760, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.600, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.520, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=1.000, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.840, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.920, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.880, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.960, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.920, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100, multi_class=ovr, solver=liblinear .........\n",
            "[CV]  C=0.01, max_iter=100, multi_class=ovr, solver=liblinear, score=0.760, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.885, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.654, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.731, total=   0.7s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.7s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.560, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.7s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.600, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.600, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.520, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.800, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=1.000, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.840, total=   0.7s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.880, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.960, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.920, total=   0.4s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs ..........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=lbfgs, score=0.760, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.885, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.654, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.731, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.560, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.520, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.600, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.760, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.600, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.520, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.800, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=1.000, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.840, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.920, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.880, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.960, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.920, total=   2.2s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=saga ...........\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=saga, score=0.760, total=   2.1s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.885, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.654, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.731, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.560, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.520, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.600, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.760, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.600, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.520, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.800, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=1.000, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.840, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.920, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.880, total=   0.5s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.960, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.920, total=   0.6s\n",
            "[CV] C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear ......\n",
            "[CV]  C=0.01, max_iter=100000, multi_class=ovr, solver=liblinear, score=0.760, total=   0.6s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.500, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.500, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.500, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l1, solver=liblinear, score=0.520, total=   0.1s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.923, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.846, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.731, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.560, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.520, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.440, total=   0.4s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.760, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.640, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.480, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.800, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=1.000, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.880, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.840, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.920, total=   0.4s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.920, total=   0.3s\n",
            "[CV] C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.720, total=   0.3s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.923, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.846, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.731, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.560, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.520, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.440, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.760, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.640, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.480, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.800, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=1.000, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.880, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.840, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.920, total=   0.2s\n",
            "[CV] C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear \n",
            "[CV]  C=0.001, dual=True, max_iter=1000, multi_class=ovr, penalty=l2, solver=liblinear, score=0.720, total=   0.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 420 out of 420 | elapsed:  3.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 0.01, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.718 (+/-0.327) for {'C': 0.0001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.719 (+/-0.334) for {'C': 0.0001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.719 (+/-0.337) for {'C': 0.0001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.718 (+/-0.327) for {'C': 0.0001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.719 (+/-0.334) for {'C': 0.0001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.719 (+/-0.337) for {'C': 0.0001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.753 (+/-0.338) for {'C': 0.001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.753 (+/-0.338) for {'C': 0.001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.771 (+/-0.292) for {'C': 0.01, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.769 (+/-0.290) for {'C': 0.01, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.769 (+/-0.290) for {'C': 0.01, 'max_iter': 100, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.771 (+/-0.292) for {'C': 0.01, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'lbfgs'}\n",
            "0.769 (+/-0.290) for {'C': 0.01, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'saga'}\n",
            "0.769 (+/-0.290) for {'C': 0.01, 'max_iter': 100000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
            "0.497 (+/-0.036) for {'C': 0.001, 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.749 (+/-0.334) for {'C': 0.001, 'dual': True, 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "Accuracy on test set=  0.9347826086956522\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        48\n",
            "           1       0.91      0.95      0.93        44\n",
            "\n",
            "    accuracy                           0.93        92\n",
            "   macro avg       0.93      0.94      0.93        92\n",
            "weighted avg       0.94      0.93      0.93        92\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fcYRch8nkvP",
        "colab_type": "text"
      },
      "source": [
        "##SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIXC54muEXi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: SGD classifier #\n",
        "SGD_param_grid = [{'loss':['hinge','log','perceptron','squared_hinge'], 'penalty': ['l2','l1']}]\n",
        "#loss = 'hinge' is equivalent to linear SVC, with SGD\n",
        "#loss = 'squared_hinge' is the same but quadratically penalized\n",
        "#loss = 'log' is equivalent to logistic Regression with SGD\n",
        "#loss = 'perceptron' is equivalent to Perceptron with SGD\n",
        "\n",
        "print(\"# SGD Classifiers: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(SGDClassifier(), SGD_param_grid, cv=5, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqZqDejKnneY",
        "colab_type": "text"
      },
      "source": [
        "##Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfUaiWlLGlZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: Naive Bayes #\n",
        "NB_clf = GaussianNB()\n",
        "print(NB_clf.get_params())\n",
        "NB_param_grid = [{'priors':[None], 'var_smoothing': [1e-09]}]\n",
        "print(\"# NB Classifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(GaussianNB(), NB_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIs8kNJnrqq",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0bAidHOPMf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: Decision Tree #\n",
        "DecTree_clf = DecisionTreeClassifier(random_state=42)\n",
        "print(DecTree_clf.get_params())\n",
        "DecTree_param_grid = [{'criterion':['gini','entropy'], 'min_samples_leaf': [1, 5, 10, 20, 50, 100], 'max_depth':[50]},\n",
        "                      {'criterion':['gini','entropy'], 'min_samples_leaf': [10], 'max_depth':[10,25,50,75,100,150]}\n",
        "                     ]\n",
        "print(\"# DecisionTreeClassifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(DecisionTreeClassifier(), DecTree_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA5oYAS0nwEv",
        "colab_type": "text"
      },
      "source": [
        "### With Bagging\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U7sSXW7Kj0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: Bagging Classifier #\n",
        "Bagging_clf = BaggingClassifier()\n",
        "print(Bagging_clf.get_params())\n",
        "Bagging_param_grid = [{'base_estimator':[DecisionTreeClassifier(criterion='entropy', max_depth=100, min_samples_leaf=10)], \n",
        "                       'bootstrap': [True, False], 'n_estimators':[10, 20, 50], 'max_samples':[1,5,10], 'max_features':[1,10,50]}\n",
        "                      #{'base_estimator':[SVC(),DecisionTreeClassifier(),RandomForestClassifier()], 'bootstrap': [True, False], 'n_estimators':[10, 50, 100]},\n",
        "                      #{'base_estimator':[SVC(),DecisionTreeClassifier(),RandomForestClassifier()], 'max_samples': [1,5,10,20]}\n",
        "                     ]\n",
        "print(\"# DecisionTreeClassifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "#scores = ['accuracy','precision', 'recall']\n",
        "scores = ['accuracy']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    clf = GridSearchCV(BaggingClassifier(), Bagging_param_grid, scoring='%s' % score, verbose=0)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFFLsHSOoE62",
        "colab_type": "text"
      },
      "source": [
        "##AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szaalPWpPRjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: AdaBoost #\n",
        "\n",
        "AdaB_clf = AdaBoostClassifier(random_state=42)\n",
        "print(AdaB_clf.get_params())\n",
        "AdaB_param_grid = [{'n_estimators':[10,30,50,100,1000], 'learning_rate':[0.01]},\n",
        "                   {'n_estimators':[100], 'learning_rate':[0.0001,0.001,0.01,0.1,1,5]}\n",
        "                  ]\n",
        "print(\"# AdaBoostClassifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(AdaBoostClassifier(), AdaB_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G47s9cr-n8WI",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfw97LV_PiTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL: Random Forest #\n",
        "RandomForest_clf = RandomForestClassifier(random_state=42)\n",
        "print(RandomForest_clf.get_params())\n",
        "RandomForest_param_grid = [{'criterion':['gini','entropy'], 'min_samples_leaf': [1, 5, 10, 20, 50, 100], 'max_depth':[50]},\n",
        "                           {'criterion':['gini','entropy'], 'min_samples_leaf': [10], 'max_depth':[10,20,30,40,50]},\n",
        "                           {'n_estimators':[10,50,100,200], 'bootstrap':[True,False]}\n",
        "                          ]\n",
        "print(\"# RandomForestClassifier: Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "scores = ['accuracy','precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(RandomForestClassifier(), RandomForest_param_grid, scoring='%s' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(\"Accuracy on test set= \", accuracy_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rx79hnlz5bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpoMDOYv_IR",
        "colab_type": "text"
      },
      "source": [
        "#Optimized Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jb_jYJ7v9iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LinSVC(X_train,X_test, y_train,y_test):\n",
        "  clf = LinearSVC(C=0.001,max_iter=100)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def SVC_(X_train,X_test, y_train,y_test):\n",
        "  clf = SVC(C=0.001,kernel='linear')\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def LogReg(X_train,X_test, y_train,y_test):\n",
        "  clf = LogisticRegression(C=0.001, max_iter=100, multi_class='ovr', solver='lbfgs')\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def naiveBayes(X_train,X_test, y_train,y_test):\n",
        "  clf = GaussianNB()\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def DecisionTree(X_train,X_test, y_train,y_test):\n",
        "  clf = DecisionTreeClassifier(criterion='entropy', max_depth=100, min_samples_leaf=10,random_state=42)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def AdaBoost(X_train,X_test, y_train,y_test):\n",
        "  clf = AdaBoostClassifier(learning_rate=0.01, n_estimators=100)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def RandomForest(X_train,X_test, y_train,y_test):\n",
        "  clf = RandomForestClassifier(criterion='gini', max_depth=20, min_samples_leaf=10)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def SGD(X_train,X_test, y_train,y_test):\n",
        "  clf = SGDClassifier(loss='hinge', penalty='l1')\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm\n",
        "\n",
        "def basic_CNN(X_train,X_test, y_train,y_test):\n",
        "  estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=10)\n",
        "  estimator.fit(X_train, y_train) \n",
        "  y_pred = estimator.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  precision  = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  return acc, precision, recall, cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewcNyh2Pc0Cw",
        "colab_type": "text"
      },
      "source": [
        "##Run classifiers on test sets\n",
        "\n",
        "Trains the classifier models with optimized parameters on the training set.\n",
        "\n",
        "Runs the models on each individual test dataset.\n",
        "\n",
        "Creates and stores results in a CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iNtAWKMbF5A",
        "colab_type": "text"
      },
      "source": [
        "### Bird motif vs data from other birds\n",
        "\n",
        "> Training set: complete dataset except for data from bird whose motif is tested\n",
        "\n",
        "> Test sets: each motif from motif dictionary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHhHOB1Y0Wx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_file = open(\"results.csv\",\"a+\") \n",
        "for test_bird in motifs_dict:\n",
        "  for test_motif in motifs_dict[test_bird]:\n",
        "\n",
        "    print(\"Testing classifiers on bird: \",test_bird,\", motif: \", test_motif, \"\\n\")\n",
        "    X_train, y_train, X_test, y_test, IDs_train, IDs_test  = split_TrainTest(concat_df, motifs_dict, test_bird, test_motif)\n",
        "    time_start = time.time()\n",
        "    print(\"Classifier: LinearSVC\")\n",
        "    acc, precision, recall, cm = LinSVC(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'LinearSVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: SVC\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SVC_(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Logistic Regression\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = LogReg(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Logistic Regression'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Naive Bayes\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = naiveBayes(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Naive Bayes'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Decision Tree\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = DecisionTree(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Decision Tree'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: AdaBoost\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = AdaBoost(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'AdaBoost'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Random Forest\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = RandomForest(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Random Forest'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)    \n",
        "    print(\"Classifier: SGD\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SGD(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SGD'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Basic CNN\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = basic_CNN(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Basic CNN'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "\n",
        "results_file.close()\n",
        "files.download('results.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLRlJSyPEan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('results.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vSMLHIGA2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decision_file = open(\"decision_fn.txt\",\"a+\") \n",
        "test_dict = {'bk109-re22or7': ['ef'],\n",
        "             're26or': ['abcd'],\n",
        "              }\n",
        "for test_bird in motifs_dict:\n",
        "  for test_motif in motifs_dict[test_bird]:\n",
        "\n",
        "    print(\"Testing classifiers on bird: \",test_bird,\", motif: \", test_motif, \"\\n\")\n",
        "    X_train, y_train, X_test, y_test, IDs_train, IDs_test  = split_TrainTest(concat_df, motifs_dict, test_bird, test_motif)\n",
        "    time_start = time.time()    \n",
        "    print(\"Classifier: Logistic Regression\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = LogReg(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Logistic Regression'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    decision_file.write(new_line)\n",
        "\n",
        "decision_file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znGs1heJX0LT",
        "colab_type": "text"
      },
      "source": [
        "### 1st vs 2nd motif for same bird\n",
        "\n",
        "> Training set: dataset from 1 motif of 1 bird\n",
        "\n",
        "> Test sets: dataset from other motif of same bird\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQ7DjyLYPHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_file = open(\"results_2.csv\",\"a+\") \n",
        "\n",
        "for test_bird in motifs_dict:\n",
        "  for test_motif in motifs_dict[test_bird]:\n",
        "    print(\"Testing classifiers on bird: \",test_bird,\", motif: \", test_motif, \"\\n\")\n",
        "    X_train, y_train, X_test, y_test, IDs_train, IDs_test  = split_TrainTest_indiv(concat_df, motifs_dict, test_bird, test_motif)\n",
        "    time_start = time.time()\n",
        "    print(\"Classifier: LinearSVC\")\n",
        "    acc, precision, recall, cm = LinSVC(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'LinearSVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: SVC\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SVC_(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Logistic Regression\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = LogReg(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Logistic Regression'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Naive Bayes\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = naiveBayes(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Naive Bayes'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Decision Tree\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = DecisionTree(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Decision Tree'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: AdaBoost\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = AdaBoost(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'AdaBoost'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Random Forest\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = RandomForest(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Random Forest'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)    \n",
        "    print(\"Classifier: SGD\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SGD(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SGD'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Basic CNN\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = basic_CNN(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Basic CNN'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "\n",
        "results_file.close()\n",
        "files.download('results_2.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39-iM14rztj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('results_2.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW4qiKGI1Ta_",
        "colab_type": "text"
      },
      "source": [
        "###Motif vs same motif (for same bird)\n",
        "\n",
        "> Training set: 67% of dataset for 1 motif of 1 bird\n",
        "\n",
        "> Test sets: 33% of same dataset (same motif, same bird)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-emMlt1cUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_file = open(\"results_3bis.csv\",\"a+\") \n",
        "\n",
        "for test_bird in motifs_dict:\n",
        "  for test_motif in motifs_dict[test_bird]:\n",
        "    motif_tag = ''+test_bird+'_'+test_motif\n",
        "    print(\"Testing classifiers on bird: \",test_bird,\", motif: \", test_motif, \"\\n\")\n",
        "    motif_df = concat_df[concat_df['bird_motif']==motif_tag]\n",
        "    #print(motif_df)\n",
        "    X,y,IDs = dfToNumpy(motif_df)\n",
        "    print(X.shape,y.shape)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    time_start = time.time()\n",
        "    print(\"Classifier: LinearSVC\")\n",
        "    acc, precision, recall, cm = LinSVC(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'LinearSVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: SVC\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SVC_(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SVC'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)\n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Logistic Regression\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = LogReg(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Logistic Regression'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Naive Bayes\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = naiveBayes(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Naive Bayes'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Decision Tree\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = DecisionTree(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Decision Tree'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: AdaBoost\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = AdaBoost(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'AdaBoost'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Random Forest\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = RandomForest(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Random Forest'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)    \n",
        "    print(\"Classifier: SGD\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = SGD(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'SGD'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "    print(\"Classifier: Basic CNN\")\n",
        "    time_start = time.time()\n",
        "    acc, precision, recall, cm = basic_CNN(X_train, X_test, y_train, y_test)\n",
        "    runtime = time.time()-time_start\n",
        "    new_line = '\\n'+test_bird+','+test_motif+','+test_bird+'_'+test_motif+','+'Basic CNN'+','+str(acc)+','+str(precision)+','+str(recall)+',['+str(cm[0])+str(cm[1])+'],'+str(runtime)    \n",
        "    print(new_line)\n",
        "    results_file.write(new_line)\n",
        "\n",
        "results_file.close()\n",
        "files.download('results_3bis.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG8IDsU5FINE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('results_3bis.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7NPGVWrtcOL",
        "colab_type": "text"
      },
      "source": [
        "#CNN: Convolutional Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjwql66vOxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "           'precision' : make_scorer(precision_score),\n",
        "           'recall' : make_scorer(recall_score)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxjBdZV0-Tl",
        "colab_type": "text"
      },
      "source": [
        "###Baseline CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkEQFJ-rcuwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model\n",
        "def create_baseline():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(1000, input_dim=X_train.shape[1], activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDi330ZctTEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "aac50abd-967b-44e0-895c-73b6b4f477f6"
      },
      "source": [
        "\n",
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=10)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "#results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
        "#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "\n",
        "results = cross_validate(estimator, X_train, y_train, cv=kfold,scoring=scoring)\n",
        "print(\"Acc = \", np.mean(results['test_accuracy']), \"+/-\",np.std(results['test_accuracy']) )\n",
        "print(\"Acc = \",np.mean(results['test_precision']), \"+/-\",np.std(results['test_precision']) )\n",
        "print(\"Acc = \",np.mean(results['test_recall']), \"+/-\",np.std(results['test_recall']) )\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2e7fbdba3a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#results = cross_val_score(estimator, X_train, y_train, cv=kfold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_baseline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rggt_LmM1Tbm",
        "colab_type": "text"
      },
      "source": [
        "###More complex CNN\n",
        "\n",
        "\n",
        "\n",
        "> Abandoned (excessive running time) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp8NdgcVtVyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# larger model\n",
        "\n",
        "def create_larger():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(1000, input_dim=X_train.shape[1], activation='relu'))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=10)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_validate(pipeline, X_train, y_train, cv=kfold,scoring=scoring)\n",
        "print(\"Acc = \", np.mean(results['test_accuracy']), \"+/-\",np.std(results['test_accuracy']) )\n",
        "print(\"Acc = \",np.mean(results['test_precision']), \"+/-\",np.std(results['test_precision']) )\n",
        "print(\"Acc = \",np.mean(results['test_recall']), \"+/-\",np.std(results['test_recall']) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t58ynxoZ0JWa",
        "colab_type": "code",
        "outputId": "78faf8fc-2c3f-4ba2-d1a9-41f9fe72c8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKoU0Bo0YSBy",
        "colab_type": "text"
      },
      "source": [
        "#Classifier performance after PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsX34ORd4fWc",
        "colab_type": "text"
      },
      "source": [
        "> Explained variance vs number of components\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7MhD-o2ldn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "bb7e35fc-d8e1-447c-e797-9158a4eb4ccf"
      },
      "source": [
        "X,y, IDs = dfToNumpy(concat_df)\n",
        "pca = PCA().fit(X)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.grid(b=True)\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.savefig('pca_explained_variance.png')\n",
        "plt.tight_layout()\n",
        "files.download('pca_explained_variance.png')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-owldwJpYXQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess dataset, split into training and test part\n",
        "X,y,ID = dfToNumpy(concat_df)\n",
        "X_train, y_train, X_test, y_test, IDs_train, IDs_test  = split_TrainTest(concat_df, motifs_dict, 'p77y27', 'abcdef')\n",
        "y_label = np.copy(y).astype(str)\n",
        "y_label[y_label == '0'] = 'UD'\n",
        "y_label[y_label == '1'] = 'FD'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZi61nXyesAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comparePCA(algo, n):\n",
        "    reduction = PCA(n_components=n)\n",
        "    x_train_reduced = reduction.fit_transform(X_train)\n",
        "    x_test_reduced = reduction.transform(X_test)\n",
        "    \n",
        "    classifier2 = algo\n",
        "    classifier2.fit(X_train, y_train)\n",
        "    y_pred2 = classifier2.predict(X_test)\n",
        "    acc = accuracy_score(y_test,y_pred2)\n",
        "    \n",
        "\n",
        "    classifier = algo\n",
        "    classifier.fit(x_train_reduced, y_train)\n",
        "    y_pred = classifier.predict(x_test_reduced)\n",
        "    acc_PCA = accuracy_score(y_test,y_pred)\n",
        "\n",
        "    #print(\"Acc with PCA= \", acc)\n",
        "    #print(\"Acc without PCA= \", acc2)\n",
        "\n",
        "    return acc_PCA, acc\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M02jUcj9pYda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5cd81925-a291-4d73-ac75-0f8d2fdf24bc"
      },
      "source": [
        "n_components = [2,5,10,50,100,250]\n",
        "pca_file = open(\"pca_comp.csv\",'a+')\n",
        "print(\"Test set,Classifier,Accuracy w/o PCA,Accuracy w/ PCA,n_components\")\n",
        "for n in n_components:\n",
        "  for test_bird in motifs_dict:\n",
        "    for test_motif in motifs_dict[test_bird]:\n",
        "      X_train, y_train, X_test, y_test, IDs_train, IDs_test  = split_TrainTest(concat_df, motifs_dict, test_bird,test_motif)\n",
        "      #print(\"Classifier: SVC\")\n",
        "      acc_PCA, acc = comparePCA(SVC(C=0.001,kernel='linear'),n)\n",
        "      pca_file.write(''+str(test_bird)+'_'+str(test_motif)+',SVC,'+str(acc)+','+str(acc_PCA)+','+str(n))\n",
        "      #print(\"Classifier: Logistic Regression\")\n",
        "      acc_PCA, acc = comparePCA(LogisticRegression(C=0.001, max_iter=100, multi_class='ovr', solver='lbfgs'),n)\n",
        "      pca_file.write(''+str(test_bird)+'_'+str(test_motif)+',Logistic Regression,'+str(acc)+','+str(acc_PCA)+','+str(n))\n",
        "\n",
        "pca_file.close()\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set,Classifier,Accuracy w/o PCA,Accuracy w/ PCA,n_components\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob47H2HB5u88",
        "colab_type": "text"
      },
      "source": [
        "## Plotting boundary lines \n",
        "\n",
        "> For PCA with n=2 components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_LysSaMopL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BoundaryLine(algo, algo_name):\n",
        "    reduction = PCA(n_components=2)\n",
        "    x_train_reduced = reduction.fit_transform(X_train)\n",
        "    x_test_reduced = reduction.transform(X_test)\n",
        "    \n",
        "    \n",
        "\n",
        "    classifier = algo\n",
        "    classifier.fit(x_train_reduced, y_train)\n",
        "    y_pred = classifier.predict(x_test_reduced)\n",
        "    acc = accuracy_score(y_test,y_pred)\n",
        "    print(\"acc=\",acc)\n",
        "    #Boundary Line\n",
        "    #X_set, y_set = np.concatenate([x_train_reduced, x_test_reduced], axis = 0), np.concatenate([y_train, y_test], axis = 0)\n",
        "    X_set, y_set= X_test, y_test\n",
        "    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "                 alpha = 0.5, cmap = ListedColormap(('orange', 'blue')))\n",
        "    plt.xlim(X1.min(), X1.max())\n",
        "    plt.ylim(X2.min(), X2.max())\n",
        "    for i, j in enumerate(np.unique(y_set)):\n",
        "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                    c = ListedColormap(('orange', 'blue'))(i), label = j)\n",
        "    plt.title('{} Boundary Line with PCA' .format(algo_name))\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.legend()\n",
        "    plt.xticks(fontsize = 3)\n",
        "    plt.yticks(fontsize = 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mycmVMV5fIxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "fe5f7fd9-fa2e-44f9-e257-ecd0cbffc9be"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "#Logistic Regression   \n",
        "ax.set_title('Linear PCA')\n",
        "ax.set_ylabel('Logistic \\n Regression', rotation = 0, labelpad=30, fontsize = 10)\n",
        "BoundaryLine(LogisticRegression(C=0.001, max_iter=100, multi_class='ovr', solver='lbfgs'), \"Logistic Regression\")\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "acc= 0.7794117647058824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGx8mqZ-itMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "46fe7f48-d643-4c6e-80a9-7e7fbe106707"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "# SVC\n",
        "ax.set_title('Linear PCA')\n",
        "ax.set_ylabel('SVC', rotation = 0, labelpad=30, fontsize = 10)\n",
        "BoundaryLine(SVC(C=0.001,kernel='linear'), \"SVC\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXd-bMmvjPjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "4f74ba67-0970-424c-dde0-4d06e3b86e69"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "#Linear SVC   \n",
        "ax.set_title('Linear PCA')\n",
        "ax.set_ylabel('LinearSVC', rotation = 0, labelpad=30, fontsize = 10)\n",
        "BoundaryLine(LinearSVC(C=0.001,max_iter=100), \"LinearSVC\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc with PCA=  0.7794117647058824\n",
            "Acc without PCA=  0.8088235294117647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}